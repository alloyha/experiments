# Curso de Modelagem de Dados com PostgreSQL

Este reposit√≥rio cont√©m o material completo do curso pr√°tico de Modelagem de Dados, indo desde os fundamentos relacionais at√© t√©cnicas avan√ßadas de Big Data Engineering e Grafos.

## üéØ Objetivo

O objetivo deste curso √© ensinar a modelar dados de forma eficiente, pragm√°tica e escal√°vel. Diferente de cursos tradicionais, aqui combinamos a teoria cl√°ssica (Kimball) com as pr√°ticas modernas das Big Techs (Netflix, Airbnb, Facebook), inspiradas nas melhores pr√°ticas de Engenharia de Dados.

## üë• P√∫blico Alvo

Este material √© destinado a:
*   **Engenheiros de Dados** que buscam consolidar conceitos de Data Warehousing e aprender padr√µes modernos de Big Data.
*   **Desenvolvedores Backend** interessados em otimiza√ß√£o de banco de dados e design de schemas robustos.
*   **Analistas de Dados/BI** que desejam entender a estrutura por tr√°s de relat√≥rios perform√°ticos.
*   **Estudantes** de computa√ß√£o que querem ir al√©m do b√°sico "SELECT * FROM".

## üìä N√≠vel do Conte√∫do

*   **N√≠vel:** Intermedi√°rio a Avan√ßado.
*   **Pr√©-requisitos:** Conhecimento b√°sico de SQL (SELECT, INSERT, JOINs).
*   **Foco:** A transi√ß√£o do Modelo Relacional (3NF) para Modelagem Dimensional (Star Schema) e t√©cnicas de **Engenharia de Dados em Escala** (Structs, Arrays, Cumulative Tables).

## üìö Estrutura do Curso

O curso √© dividido em 10 aulas pr√°ticas, cada uma contendo:
*   `apresentacao.sql`: Conceitos e exemplos explicados.
*   `exercicios.sql`: Desafios para fixa√ß√£o.
*   `gabarito.sql`: Solu√ß√£o comentada.

### M√≥dulos

*   **Aula 01: Introdu√ß√£o** - OLTP vs OLAP, Modelagem Conceitual/L√≥gica/F√≠sica.
*   **Aula 02: ERD (Entity Relationship Diagrams)** - Entidades, Atributos, Normaliza√ß√£o (1NF, 2NF, 3NF).
*   **Aula 03: Pr√°tica de ERD** - Modelagem completa de um sistema de Biblioteca.
*   **Aula 04: Introdu√ß√£o Dimensional** - Star Schema vs Snowflake, Fatos e Dimens√µes.
*   **Aula 05: Tabelas Fato & Big Data** - Fatos Transacionais, Snapshots e **Cumulative Tables** (State Management).
*   **Aula 06: Tabelas Dimens√£o** - Dimens√µes, Hierarquias e **Structs/Arrays** para eliminar Joins.
*   **Aula 07: Bridge Tables & Array Metrics** - Resolvendo relacionamentos N:N com tabelas ponte e Arrays.
*   **Aula 08: SCD (Slowly Changing Dimensions)** - Tipos 0, 1, 2, 3 e estrat√©gias de performance.
*   **Aula 09: Implementa√ß√£o de SCD Type 2** - O padr√£o cl√°ssico vs **Nested History** (Hist√≥rico numa √∫nica linha).
*   **Aula 10: Modelagem de Grafos** - Quando o relacional falha: modelando redes complexas.

## üöÄ Como Executar

Este projeto utiliza **Docker** para subir um ambiente PostgreSQL pronto para uso.

### Pr√©-requisitos
*   Docker & Docker Compose instalados.
*   Um cliente SQL (DBeaver, VSCode SQLTools, Datagrip) ou terminal (`psql`).

### Passo a Passo

1.  **Subir o Banco de Dados:**
    ```bash
    docker compose up -d
    ```
    Isso iniciar√° um container PostgreSQL e executar√° automaticamente o script `setup_database.sql`, criando as tabelas base e inserindo dados de exemplo.

2.  **Conectar ao Banco:**
    *   **Host:** `localhost`
    *   **Port:** `5432`
    *   **Database:** `curso_modelagem`
    *   **User:** `aluno`
    *   **Password:** `modelagem_password`

3.  **Explorar as Aulas:**
    Navegue pelas pastas `aula_XX` e execute os scripts SQL no seu cliente favorito.

## üåü Destaques "Big Data"

Al√©m do curr√≠culo tradicional de Data Warehousing, este curso inclui adapta√ß√µes para **Engenharia de Dados em Escala (Big Data)**:

*   **Cumulative Table Design:** "Yesterday + Today = Tomorrow". Como gerenciar estado de usu√°rios sem scans hist√≥ricos massivos.
*   **Array Metrics:** Substitui√ß√£o de Bridge Tables custosas por Arrays desnormalizados.
*   **Nested Data (Structs):** Como compactar hist√≥rico de SCD Type 2 em uma √∫nica linha para evitar Shuffle em processamento distribu√≠do (Spark/Trino).
*   **Idempot√™ncia:** Uso de `INSERT ON CONFLICT` para garantir pipelines robustos.

---
*Material desenvolvido para estudo e pr√°tica de engenharia de dados.*
